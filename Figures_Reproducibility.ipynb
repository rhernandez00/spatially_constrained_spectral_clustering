{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "reload(figure_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Segmentation vs segmentation. This will create a csv file for each number of clusters and each permutation test\n",
    "# This will generate a csv file for each number of clusters. If rnd each repetition of the permutation test as well\n",
    "# Last used 8/Jun/2025 to get Johnson_gyri and Johnson_lobe\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "reload(figure_utils)\n",
    "\n",
    "# running get clusters\n",
    "comp_names = ['beagle','others','all','healthy', 'Johnson', 'Johnson_gyri', 'Johnson_lobe', 'Knee']\n",
    "comp_N = 7 # 7 for Knee, 0 for epi1, 1 for epi2, 2 for epi, 3 for healthy\n",
    "rnd = False # True for individual permutations per segment, False for original data\n",
    "username = 'raulh87'\n",
    "dataset = 'CAPS_K9'\n",
    "local_data=True\n",
    "\n",
    "if rnd == False:\n",
    "    n_reps = 0\n",
    "else:\n",
    "    n_reps = 1000\n",
    "\n",
    "project_dict_test = figure_utils.get_project_dict(comp_names[comp_N])[0]\n",
    "project_dict_base = figure_utils.get_project_dict('K9')[0]\n",
    "\n",
    "experiment = 'CAPS'\n",
    "if rnd:\n",
    "    results_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results_rnd\"\n",
    "else:\n",
    "    results_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\"\n",
    "\n",
    "\n",
    "for number_of_clusters in [20,40,60,80,100,120,140,160,180,200,220,240,260,280,300]:\n",
    "    # get a list of files matching the number of cluster and any permutation\n",
    "    clusters_test,clusters_ID_test = figure_utils.get_clusters(project_dict_test, number_of_clusters)\n",
    "    if rnd == False:\n",
    "        perms_numbers = [0]\n",
    "    else:\n",
    "        perms_numbers = figure_utils.which_cluster_files(project_dict_base, number_of_clusters)\n",
    "    # print number of permutations available\n",
    "    print('Number of permutations available: ' + str(len(perms_numbers)))\n",
    "    for rnd_N in perms_numbers:\n",
    "        if rnd == False and rnd_N != 0: # only run once for original data\n",
    "            data_table_path = os.path.join(results_path, 'data_table_' + str(number_of_clusters) + '_' + comp_names[comp_N] + '.csv')\n",
    "            break\n",
    "        else:\n",
    "            data_table_path = os.path.join(results_path, 'data_table_' + str(number_of_clusters) + '_' + comp_names[comp_N] + '_' + str(rnd_N).zfill(4) + '.csv')\n",
    "            # clear the output\n",
    "            os.system('cls' if os.name == 'nt' else 'clear')\n",
    "            print('Running for ' + str(rnd_N) + 'th repetition out of ' + str(len(perms_numbers)))\n",
    "        # check if data_table_path exists, if it does, skip this iteration\n",
    "        if os.path.exists(data_table_path):\n",
    "            print('Data table already exists: ' + data_table_path, 'Skipping...')\n",
    "            continue\n",
    "\n",
    "        # check if data_table_path folder exists, if not create it\n",
    "        if not os.path.exists(os.path.dirname(data_table_path)):\n",
    "            os.makedirs(os.path.dirname(data_table_path))\n",
    "\n",
    "        \n",
    "        clusters_base,clusters_ID_base = figure_utils.get_clusters(project_dict_base, number_of_clusters, rnd, rnd_N)\n",
    "\n",
    "        # initialize data_table\n",
    "        data_table = pd.DataFrame(columns=['ID_epi', 'N_voxels_epi', 'ID_K9', 'N_voxels_K9', 'Union', 'Dice_coeff', 'Overlap', 'Index', 'Expected_index', 'Max_index', 'ARI'])\n",
    "\n",
    "        # calculate total number of voxels\n",
    "        n_voxels = sum(len(v) for v in clusters_test.values())\n",
    "        n_voxels2 = sum(len(v) for v in clusters_base.values())\n",
    "        # make sure the number of voxels is the same, if not, raise an error\n",
    "        if n_voxels != n_voxels2:\n",
    "            print('n_voxels_epi: ' + str(n_voxels))\n",
    "            print('n_voxels_K9: ' + str(n_voxels2))\n",
    "            raise ValueError('The number of voxels in the two cluster maps is different')\n",
    "\n",
    "        for n_epi in clusters_ID_test:\n",
    "            for n_K9 in clusters_ID_base:\n",
    "                dice_coeff = 2*len(set(clusters_test[n_epi]) & set(clusters_base[n_K9]))/(len(clusters_test[n_epi]) + len(clusters_base[n_K9]))\n",
    "                # For Adjusted Rand Index\n",
    "                overlap = len(set(clusters_test[n_epi]) & set(clusters_base[n_K9]))\n",
    "                index = comb(overlap, 2)\n",
    "                sum_a = len(clusters_test[n_epi])\n",
    "                sum_b = len(clusters_base[n_K9])\n",
    "                expected = comb(sum_a, 2) * comb(sum_b, 2) / comb(n_voxels, 2)\n",
    "                max_index = 0.5 * (comb(sum_a, 2) + comb(sum_b, 2))\n",
    "                ari = (index - expected) / (max_index - expected) if max_index != expected else 0\n",
    "\n",
    "\n",
    "                new_row = {\n",
    "                    'ID_epi': n_epi,\n",
    "                    'N_voxels_epi': len(clusters_test[n_epi]),\n",
    "                    'ID_K9': n_K9,\n",
    "                    'N_voxels_K9': len(clusters_base[n_K9]),\n",
    "                    'Union': len(set(clusters_test[n_epi]) & set(clusters_base[n_K9])),\n",
    "                    'Dice_coeff': dice_coeff,\n",
    "                    'Overlap': overlap,\n",
    "                    'Index': index,\n",
    "                    'Expected_index': expected,\n",
    "                    'Max_index': max_index,\n",
    "                    'ARI': ari,\n",
    "                }\n",
    "                # add the new row to the data_table\n",
    "                data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # Clean up table\n",
    "        # filter out the rows with Overlap = 0\n",
    "        data_table = data_table[data_table['Overlap'] != 0]\n",
    "        # sort the data_table by Overlap\n",
    "        data_table = data_table.sort_values(by='Overlap', ascending=False)\n",
    "        # add number of repetitions to the table\n",
    "        data_table['rnd_N'] = rnd_N\n",
    "\n",
    "        # save the data_table\n",
    "        data_table.to_csv(data_table_path, index=False)\n",
    "        print('Data table saved to: ' + data_table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine to a single table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges all the reproducibility stats calculated in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Use Kuhn-Munkres for best assigment and join in single table\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "reload(figure_utils)\n",
    "\n",
    "comp_dicts = {'healthy': figure_utils.get_project_dict('healthy')[0],\n",
    "              'Johnson': figure_utils.get_project_dict('Johnson')[0],\n",
    "              'Johnson_gyri': figure_utils.get_project_dict('Johnson_gyri')[0],\n",
    "              'Johnson_lobe': figure_utils.get_project_dict('Johnson_lobe')[0],\n",
    "              'Knee': figure_utils.get_project_dict('Knee')[0],\n",
    "              }\n",
    "\n",
    "comp_dicts_keys = ['healthy', 'Johnson', 'Johnson_gyri', 'Johnson_lobe', 'Knee']\n",
    "\n",
    "results_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\"\n",
    "\n",
    "number_of_clusters_list = [20,40,60,80,100,120,140,160,180,200,220,240,260,280,300]\n",
    "\n",
    "\n",
    "for comp_type in comp_dicts_keys:\n",
    "    # create an empty dataframe to store the results\n",
    "    final_table = pd.DataFrame()\n",
    "    print('Comp type: ' + comp_type)\n",
    "    # list of number of clusters\n",
    "    \n",
    "\n",
    "    for number_of_clusters in number_of_clusters_list:\n",
    "        # get the data_table_path\n",
    "        data_table_path = os.path.join(results_path, 'data_table_' + str(number_of_clusters) + '_' + comp_type + '_0000.csv')\n",
    "        # load the data_table\n",
    "        data_table = pd.read_csv(data_table_path)\n",
    "        # fill_missing_pairs\n",
    "        data_table = figure_utils.fill_missing_pairs(data_table)\n",
    "\n",
    "\n",
    "        # filter using Kuhn-Munkres\n",
    "        data_table_sel = figure_utils.best_assignment_Kuhn(data_table)\n",
    "\n",
    "        # Add number of clusters to the data_table\n",
    "        data_table_sel['N_clusters'] = number_of_clusters\n",
    "\n",
    "        final_table = pd.concat([final_table, data_table_sel], ignore_index=True)\n",
    "    # final table file name\n",
    "    final_table_path = os.path.join(results_path, 'table_' + comp_type + '.csv')\n",
    "    # save the final_table\n",
    "    final_table.to_csv(final_table_path, index=False)\n",
    "    print('Table saved to: ' + final_table_path)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure D - Johnson Comparisons\n",
    "# Generate scatter plot, x number of clusters, y Dice_coeff.\n",
    "# Clear all the variables\n",
    "%reset -f\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "reload(figure_utils)\n",
    "import matplotlib.ticker as mticker   # ← new import\n",
    "\n",
    "figure_letter = 'D'\n",
    "grid_spacing = 0.03\n",
    "username = 'raulh87'\n",
    "vars_to_use = ['Dice_coeff']\n",
    "\n",
    "comp_names = ['Johnson','Johnson_gyri','Johnson_lobe']\n",
    "# x_shift = [0, 1, 2]  # Shift for each comparison to avoid overlap in the x-axis\n",
    "\n",
    "save_file = True\n",
    "color_comb = 'white' # tales 'white' or 'black'\n",
    "\n",
    "if color_comb == 'white':\n",
    "    opposite_color = 'black'\n",
    "elif color_comb == 'black':\n",
    "    opposite_color = 'white'\n",
    "else:\n",
    "    raise ValueError('color_comb must be white or black')\n",
    "\n",
    "dataset = 'CAPS_K9'\n",
    "experiment = 'CAPS'\n",
    "figure_dims = (10, 1)\n",
    "project_dict = figure_utils.get_project_dict('K9')[0]\n",
    "figures_folder = figure_utils.get_path('Figures', project_dict, figure_letter=figure_letter)\n",
    "# create figure\n",
    "fig, ax = plt.subplots(figsize=figure_dims)\n",
    "# initialize min_ylist and max_y_list\n",
    "min_y_list, max_y_list = [], []\n",
    "for comp in comp_names:\n",
    "    # get project_dict for the comparison\n",
    "    project_dict_comp = figure_utils.get_project_dict(comp)[0]\n",
    "    # Make a plot for each stat\n",
    "    # res_path = r\"G:\\My Drive\\Results\\CAPS\\cluster_stats\\table_all.csv\"\n",
    "    res_path = r\"G:\\My Drive\\Results\\CAPS\\cluster_stats\\table_\" + comp + \".csv\"\n",
    "    # Load the res_df\n",
    "    res_df = pd.read_csv(res_path)\n",
    "    cluster_possible_list = res_df['N_clusters'].unique()\n",
    "    res_by_n_clusters = pd.DataFrame()\n",
    "    for N_clusters in cluster_possible_list:\n",
    "        # Create a figure according to figure_dims\n",
    "        res_df_sel = res_df[res_df['N_clusters'] == N_clusters]\n",
    "        new_row = {\n",
    "            'number_of_clusters': N_clusters,\n",
    "            'Dice_coeff': np.mean(res_df_sel['Dice_coeff'].values),\n",
    "        }\n",
    "        # add new_row to res_by_n_clusters\n",
    "        res_by_n_clusters = pd.concat([res_by_n_clusters, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    # setup path to save the table\n",
    "    res_table_path = r\"G:\\My Drive\\Results\\CAPS\\cluster_stats\\table_per_N_clusters_\" + comp + \".csv\"\n",
    "    # save the res_by_n_clusters\n",
    "    res_by_n_clusters.to_csv(res_table_path, index=False)\n",
    "    print('Table with average Dice coeff per number of clusters saved to: ' + res_table_path)\n",
    "    # create figure\n",
    "    # fig, ax = plt.subplots(figsize=figure_dims)\n",
    "    # get the y values and x values\n",
    "    y_values = res_by_n_clusters['Dice_coeff'].values\n",
    "    x_values = res_by_n_clusters['number_of_clusters'].values\n",
    "    # shift x values to avoid overlap\n",
    "    # x_values = x_values + x_shift[comp_names.index(comp)]\n",
    "\n",
    "    # plot the data\n",
    "    ax.plot(x_values, y_values, 'o-', label='Data', color=project_dict_comp['color'])\n",
    "    \n",
    "    # add min_y and max_y to lists\n",
    "    min_y_list.append(np.min(y_values))\n",
    "    max_y_list.append(np.max(y_values))\n",
    "\n",
    "\n",
    "    # min_y_list = min(y_values)\n",
    "    # max_y_list = max(y_values)\n",
    "\n",
    "min_y = min(min_y_list)\n",
    "max_y = max(max_y_list)\n",
    "# define percentage to add to the y-axis\n",
    "perc = 0.1\n",
    "\n",
    "# add 10% of the y-axis\n",
    "# if min_y < 0:\n",
    "#     min_y = min_y + min_y*perc\n",
    "# else:\n",
    "#     min_y = min_y - min_y*perc\n",
    "if max_y < 0:\n",
    "    max_y = max_y - max_y*perc\n",
    "else:\n",
    "    max_y = max_y + max_y*perc\n",
    "\n",
    "\n",
    "# round min_y to the nearest 0.1\n",
    "min_y = 0#round(min_y - 0.01, 2)\n",
    "\n",
    "# round max_y to the nearest 0.1\n",
    "max_y = round(max_y + 0.01, 2)\n",
    "max_y = 0.20\n",
    "\n",
    "ax.set_ylim([min_y, max_y])\n",
    "\n",
    "# ─────────────── y-axis ticks & grid ───────────────\n",
    "# major ticks: just min and max\n",
    "ax.yaxis.set_major_locator(mticker.FixedLocator([min_y, max_y]))\n",
    "# minor ticks: every grid_spacing\n",
    "ax.yaxis.set_minor_locator(mticker.MultipleLocator(grid_spacing))\n",
    "# draw grid only at minor ticks\n",
    "ax.grid(which='minor', color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "# optionally turn off any major grid\n",
    "ax.grid(which='major', color='none')\n",
    "\n",
    "# ensure only major tick labels appear\n",
    "ax.tick_params(axis='y', which='minor', length=0)\n",
    "\n",
    "# Set the background color to none\n",
    "ax.set_facecolor('none')\n",
    "\n",
    "for spine in ['top','left','right','bottom']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "# hide x-axis ticks and labels\n",
    "ax.tick_params(axis='x', colors='none')\n",
    "# color the y-axis labels\n",
    "ax.tick_params(axis='y', colors=opposite_color)\n",
    "\n",
    "margin = 0.01\n",
    "ax.set_ylim(min_y - margin, max_y + margin)\n",
    "\n",
    "# Determine path\n",
    "figure_path = os.path.join(figures_folder, 'Dice_coeff_Johnson_three' + '.png')\n",
    "if save_file:\n",
    "    # check if folder exists, if not create it\n",
    "    if not os.path.exists(figures_folder):\n",
    "        os.makedirs(figures_folder)\n",
    "        print('Folder created: ' + figures_folder)\n",
    "\n",
    "    # Save the figure with transparency\n",
    "    fig.savefig(figure_path, transparent=True)\n",
    "    print('Figure saved to: ' + figure_path)\n",
    "else:\n",
    "    print(figure_path + ' not saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure C - Reproducibility\n",
    "# Generate scatter plot, x number of clusters, y Dice_coeff. Distribution of Dice coeff added below\n",
    "# This version creates a single plot for each comparison type (e.g., Johnson_gyri, Johnson_lobe)\n",
    "# 8/Sep/2025\n",
    "\n",
    "# Clear all the variables\n",
    "%reset -f\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "reload(figure_utils)\n",
    "import matplotlib.ticker as mticker   # ← new import\n",
    "\n",
    "figure_letter = 'C'\n",
    "grid_spacing = 0.03\n",
    "username = 'raulh87'\n",
    "vars_to_use = ['Dice_coeff', 'ARI']\n",
    "vars_to_use = ['Dice_coeff']\n",
    "stat_to_plot = 'z' # m: mean or z: for z-score\n",
    "comp_names = ['all','healthy','Johnson','Johnson_gyri','Johnson_lobe']\n",
    "comp_names = ['all','healthy','Johnson','Johnson_gyri','Johnson_lobe', 'Knee']\n",
    "comp_names = ['healthy','Knee']\n",
    "# generate dict for each comp_names with min_y, max_y. All have NaN\n",
    "y_limits_dict = {comp: {'min_y': np.nan, 'max_y': np.nan} for comp in comp_names}\n",
    "## set healthy props. to 0.40 and 0.70\n",
    "y_limits_dict['healthy']['min_y'] = 0.40\n",
    "y_limits_dict['healthy']['max_y'] = 0.70\n",
    "\n",
    "## set Knee props. to 0.40 and 0.70\n",
    "y_limits_dict['Knee']['min_y'] = 0.40\n",
    "y_limits_dict['Knee']['max_y'] = 0.70\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_file = True\n",
    "color_comb = 'white' # tales 'white' or 'black'\n",
    "\n",
    "if color_comb == 'white':\n",
    "    opposite_color = 'black'\n",
    "elif color_comb == 'black':\n",
    "    opposite_color = 'white'\n",
    "else:\n",
    "    raise ValueError('color_comb must be white or black')\n",
    "\n",
    "dataset = 'CAPS_K9'\n",
    "experiment = 'CAPS'\n",
    "figure_dims = (10, 1)\n",
    "project_dict = figure_utils.get_project_dict('K9')[0]\n",
    "figures_folder = r\"C:\\github\\spatially_constrained_spectral_clustering\\Figures\\Figure_\" + figure_letter\n",
    "\n",
    "for comp in comp_names:\n",
    "    # Make a plot for each stat\n",
    "    res_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\cluster_stats\\table_\" + comp + \".csv\"\n",
    "    # Load the res_df\n",
    "    res_df = pd.read_csv(res_path)\n",
    "    cluster_possible_list = res_df['N_clusters'].unique()\n",
    "    res_by_n_clusters = pd.DataFrame()\n",
    "    for N_clusters in cluster_possible_list:\n",
    "        # Create a figure according to figure_dims\n",
    "        res_df_sel = res_df[res_df['N_clusters'] == N_clusters]\n",
    "        new_row = {\n",
    "            'number_of_clusters': N_clusters,\n",
    "            'Dice_coeff': np.mean(res_df_sel['Dice_coeff'].values),\n",
    "        }\n",
    "        # add new_row to res_by_n_clusters\n",
    "        res_by_n_clusters = pd.concat([res_by_n_clusters, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    # setup path to save the table\n",
    "    res_table_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\cluster_stats\\table_per_N_clusters_\" + comp + \".csv\"\n",
    "    # save the res_by_n_clusters\n",
    "    res_by_n_clusters.to_csv(res_table_path, index=False)\n",
    "    print('Table with average Dice coeff per number of clusters saved to: ' + res_table_path)\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=figure_dims)\n",
    "    # get the y values and x values\n",
    "    y_values = res_by_n_clusters['Dice_coeff'].values\n",
    "    x_values = res_by_n_clusters['number_of_clusters'].values\n",
    "    # plot the data\n",
    "    ax.plot(x_values, y_values, 'o-', label='Data', color=opposite_color)\n",
    "    \n",
    "    # get min_y and max_y\n",
    "    min_y = min(y_values)\n",
    "    max_y = max(y_values)\n",
    "    # define percentage to add to the y-axis\n",
    "    perc = 0.1\n",
    "    \n",
    "    # add 10% of the y-axis\n",
    "    if min_y < 0:\n",
    "        min_y = min_y + min_y*perc\n",
    "    else:\n",
    "        min_y = min_y - min_y*perc\n",
    "    if max_y < 0:\n",
    "        max_y = max_y - max_y*perc\n",
    "    else:\n",
    "        max_y = max_y + max_y*perc\n",
    "   \n",
    "\n",
    "    # round min_y to the nearest 0.1\n",
    "    min_y = round(min_y - 0.01, 2)\n",
    "    \n",
    "    # round max_y to the nearest 0.1\n",
    "    max_y = round(max_y + 0.01, 2)\n",
    "\n",
    "    # if min_y <= 0.1 make it zero\n",
    "    if min_y <= 0.1:\n",
    "        min_y = 0\n",
    "\n",
    "    # overwrite if min_x is not nan for this comp\n",
    "    if not np.isnan(y_limits_dict[comp]['min_y']):\n",
    "        min_y = y_limits_dict[comp]['min_y']\n",
    "    if not np.isnan(y_limits_dict[comp]['max_y']):\n",
    "        max_y = y_limits_dict[comp]['max_y']\n",
    "\n",
    "    ax.set_ylim([min_y, max_y])\n",
    "\n",
    "    # ─────────────── y-axis ticks & grid ───────────────\n",
    "    # major ticks: just min and max, pad two decimals\n",
    "    ax.yaxis.set_major_locator(mticker.FixedLocator([min_y, max_y]))\n",
    "    # minor ticks: every grid_spacing\n",
    "    ax.yaxis.set_minor_locator(mticker.MultipleLocator(grid_spacing))\n",
    "    # # Format y-axis tick labels to always show two decimals\n",
    "    ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2f'))\n",
    "    # ax.yaxis.set_minor_formatter(mticker.FormatStrFormatter('%.2f'))\n",
    "    \n",
    "    # draw grid only at minor ticks\n",
    "    ax.grid(which='minor', color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    # optionally turn off any major grid\n",
    "    ax.grid(which='major', color='none')\n",
    "    \n",
    "    # ensure only major tick labels appear\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "\n",
    "    # Set the background color to none\n",
    "    ax.set_facecolor('none')\n",
    "\n",
    "    for spine in ['top','left','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    # hide x-axis ticks and labels\n",
    "    ax.tick_params(axis='x', colors='none')\n",
    "    # color the y-axis labels\n",
    "    ax.tick_params(axis='y', colors=opposite_color)\n",
    "    \n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Determine path\n",
    "    figure_path = os.path.join(figures_folder, comp + '_' + 'Dice_coeff' + '.png')\n",
    "    if save_file:\n",
    "        # check if folder exist\n",
    "        if not os.path.exists(figures_folder):\n",
    "            os.makedirs(figures_folder)\n",
    "        # Save the figure with transparency\n",
    "        fig.savefig(figure_path, transparent=True)\n",
    "        print('Figure saved to: ' + figure_path)\n",
    "    else:\n",
    "        print(figure_path + ' not saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure C. Brain slices with segments colored by cluster number\n",
    "# Each slice will have all clusters matching each number of clusters and show Dice_coeff per segment\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy  # Added import\n",
    "from importlib import reload\n",
    "import figure_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable, get_cmap\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "figure_letter = 'A'\n",
    "\n",
    "# Add options\n",
    "zero_transparent = True  # If True, zeros in segment_map and slice_base are set to np.nan\n",
    "nan_transparent = True   # If True, NaNs in segment_map are plotted as transparent; if False, print \"decision pending\"\n",
    "alpha = 1.0               # Transparency of overlay\n",
    "stat_to_plot = 'z' # m: mean or z: for z-score\n",
    "variable_name = 'Homogeneity'  # 'Homogeneity' \n",
    "write_nii = True # If True, write the nii file\n",
    "write_file=True\n",
    "clear_background=True\n",
    "alphabetic_slides = True\n",
    "\n",
    "# plot details\n",
    "font_family='Arial'\n",
    "font_size=20\n",
    "font_color = 'white'\n",
    "cmap_name = 'hot' # takes hot bwr \n",
    "simetrical_cmap = False # If True, the cmap will be simetrical\n",
    "local_data = True\n",
    "\n",
    "specie = 'D'\n",
    "\n",
    "comp_names = ['Knee','healthy', 'Johnson', 'Johnson_gyri', 'Johnson_lobe']\n",
    "\n",
    "results_output_folder = r\"C:\\github\\spatially_constrained_spectral_clustering\\Figures\"\n",
    "\n",
    "var = 'Dice_coeff'\n",
    "\n",
    "min_val_assigned = []\n",
    "max_val_assigned = []\n",
    "\n",
    "project_dict = figure_utils.get_project_dict('K9')[0]\n",
    "figure_letter = 'A'\n",
    "# figures_output_folder = r\"G:\\My Drive\\Results\\CAPS\\Figures\\Figure_A\"\n",
    "\n",
    "figures_output_folder = figure_utils.get_path('Figures', project_dict, figure_letter)\n",
    "nii_folder = os.path.join(results_output_folder, \"Figure_\" + figure_letter)\n",
    "\n",
    "img_type = \"b_GreyMatter2mm\"\n",
    "base_img = \"Czeibert_brain2mm\"\n",
    "atlas_type = project_dict['Atlas_type']\n",
    "\n",
    "\n",
    "slice_params = {\n",
    "    'z': [32],\n",
    "    'cmap': cmap_name,\n",
    "}\n",
    "cmap_type = slice_params['cmap']\n",
    "\n",
    "cluster_list = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 300]\n",
    "\n",
    "# iterate over each possible comparison\n",
    "for comp_name in comp_names:\n",
    "    res_df_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\table_\" + comp_name + \".csv\"\n",
    "    # load res_df\n",
    "    res_df = pd.read_csv(res_df_path)\n",
    "    # get the unique values of the variable\n",
    "    unique_vals = res_df[var].unique()\n",
    "    # get the min and max values\n",
    "    min_val = np.min(unique_vals)\n",
    "    max_val = np.max(unique_vals)\n",
    "    \n",
    "    # if min_val_assigned is not empty\n",
    "    # check if min_val_assigned is not empty\n",
    "    if min_val_assigned:\n",
    "    # if len(min_val_assigned) > 0: # check if min_val_assigned is not empty\n",
    "        # assign min_val\n",
    "        print('Min value assigned')\n",
    "        min_val = min_val_assigned\n",
    "    # check if max_val_assigned is not empty\n",
    "    if max_val_assigned:\n",
    "    # if len(max_val_assigned) > 0: # check if max_val_assigned is not empty\n",
    "        # assign max_val\n",
    "        max_val = max_val_assigned\n",
    "    # print the min and max values\n",
    "    print('Min value: ' + str(min_val))\n",
    "    print('Max value: ' + str(max_val))\n",
    "    \n",
    "    # go through the res_df and assign create slice (or single slice) for each number of clusters\n",
    "    for number_of_clusters in cluster_list:\n",
    "    # for number_of_clusters in cluster_list:\n",
    "        segment_map_path = os.path.join(\n",
    "                figure_utils.get_datafolder(username, local_data),\n",
    "                project_dict['Dataset'],\n",
    "                'hierarchical_clustering',\n",
    "                f\"{specie}-group-tcorr-{img_type}_{number_of_clusters}.nii.gz\"\n",
    "            )\n",
    "        # filter by number of clusters\n",
    "        res_df_sel = res_df[res_df['N_clusters'] == number_of_clusters]\n",
    "\n",
    "        try:\n",
    "            res_df_sel = res_df_sel[~res_df_sel['ID_K9'].str.startswith('__DUMMY')]\n",
    "        #catch\n",
    "        except:\n",
    "            print(f\"'ID_K9' dummy not found in res_df_sel for {comp_name} with {number_of_clusters} clusters.\")\n",
    "            \n",
    "\n",
    "        cluster_ID_list = res_df_sel['ID_K9'].unique()\n",
    "        \n",
    "        # Load the data map\n",
    "        segment_map = nib.load(segment_map_path).get_fdata()\n",
    "\n",
    "        # Convert segment_map to float if necessary\n",
    "        segment_map = segment_map.astype(float)\n",
    "   \n",
    "        # Define the colormap matplotlib.colormaps.get_cmap(obj)\n",
    "        cmap = plt.colormaps.get_cmap(cmap_type)  # Choose your colormap, e.g., 'viridis', 'plasma', 'coolwarm', etc.\n",
    "        norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "        # Create a scalar map to map values to colors\n",
    "        scalar_map = ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "        # Map unique_vals to colors\n",
    "        cmap_overlay = scalar_map.to_rgba(unique_vals)\n",
    "\n",
    "        # find where to place zero\n",
    "        zero_index = np.searchsorted(unique_vals, 0)\n",
    "\n",
    "        # add a row with alpha = 0 in zero_index\n",
    "        # cmap_overlay = np.insert(cmap_overlay, zero_index, [0, 0, 0, 0], axis=0)\n",
    "        cmap_overlay = ListedColormap(cmap_overlay)\n",
    "\n",
    "        slice_dict = {\n",
    "            'atlas_type': 'Nitzsche',\n",
    "            'z': slice_params['z'],\n",
    "            'cmap': cmap_overlay,\n",
    "            'specie': 'D',\n",
    "        }\n",
    "\n",
    "        # initialize data_map\n",
    "        data_map = np.zeros(segment_map.shape)\n",
    "\n",
    "        # loop through each cluster\n",
    "        for cluster_ID in cluster_ID_list:\n",
    "            # check if cluster_ID is in missing_clusters_IDs\n",
    "            # get the value from res_df\n",
    "            val = res_df_sel[res_df_sel['ID_K9'] == cluster_ID][var].values[0]\n",
    "            # print the value\n",
    "            # print('Cluster ID: ' + str(cluster_ID) + ' ' + var + ' Z-score: ' + str(val))\n",
    "            # assign the value to the cluster in data_map\n",
    "            data_map[segment_map == float(cluster_ID)] = val\n",
    "        # prefix_out = 'test'\n",
    "        prefix_out = f\"{comp_name}_{var}_{number_of_clusters}\"\n",
    "        figure_utils.plot_slice2(project_dict, prefix_out, figure_letter, slice_dict, data_map, alpha, alphabetic_slides, write_file, clear_background)\n",
    "        # ----- Save the data_map as a NIfTI file-----\n",
    "        # save data_map as nifti file\n",
    "        nii = nib.Nifti1Image(data_map, affine=np.eye(4))\n",
    "        # check if the folder exists, if not create it\n",
    "        if not os.path.exists(nii_folder):\n",
    "            os.makedirs(nii_folder)\n",
    "            # print message\n",
    "            print(f\"Folder {nii_folder} created\")\n",
    "        if write_nii:\n",
    "            # save the nii file\n",
    "            nib.save(nii, os.path.join(nii_folder, f\"{specie}_{comp_name}_cluster_{number_of_clusters}.nii.gz\"))\n",
    "            # print message\n",
    "            print(f\"File saved in {os.path.join(nii_folder, f'{specie}_{comp_name}_cluster_{number_of_clusters}.nii.gz')}\")\n",
    "        else:\n",
    "            print(f\"File {os.path.join(nii_folder, f'{specie}_{comp_name}_cluster_{number_of_clusters}.nii.gz')} not saved\")\n",
    "\n",
    "        # ---- Save the data_map as a NIfTI file-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of Adjusted rand index \n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "reload(figure_utils)\n",
    "\n",
    "# running get clusters\n",
    "comp_names = ['beagle','healthy','Johnson', 'Johnson_gyri', 'Johnson_lobe']\n",
    "\n",
    "\n",
    "\n",
    "res = pd.DataFrame()\n",
    "\n",
    "for comp_name in comp_names:\n",
    "    project_dict_test = figure_utils.get_project_dict(comp_name)[0]\n",
    "    project_dict_base = figure_utils.get_project_dict('K9')[0]\n",
    "    print('Comp name: ' + comp_name)\n",
    "    for number_of_clusters in [20,40,60,80,100,120,140,160,180,200,220,240,260,280,300]:\n",
    "        print('Number of clusters: ' + str(number_of_clusters))\n",
    "\n",
    "        clusters_base,clusters_ID_base = figure_utils.get_clusters(project_dict_base, number_of_clusters, rnd=False, rnd_N=0, local_data=True)\n",
    "        clusters_test,clusters_ID_test = figure_utils.get_clusters(project_dict_test, number_of_clusters, filter_with_mask=True, local_data=True)\n",
    "\n",
    "        voxel_list = []\n",
    "\n",
    "        # count total number of voxels\n",
    "        total_voxels = 0\n",
    "        for cluster in clusters_base:\n",
    "            total_voxels += len(clusters_base[cluster])\n",
    "            # add each voxel from cluster to the voxel_list\n",
    "            for voxel in clusters_base[cluster]:\n",
    "                voxel_list.append(voxel)\n",
    "\n",
    "        # create segmentation_base and segmentation_test based on the total number of voxels\n",
    "        segmentation_base = np.zeros(total_voxels)\n",
    "        segmentation_test = np.zeros(total_voxels)\n",
    "        # assign the cluster number to each voxel in the segmentation_base\n",
    "        for cluster_ID in clusters_base.keys():\n",
    "            # get the cluster\n",
    "            cluster = clusters_base[cluster_ID]\n",
    "            # assign the cluster number to each voxel in the segmentation_base\n",
    "            for voxel in cluster:\n",
    "                # find position of voxel in the voxel_list\n",
    "                pos = voxel_list.index(voxel)\n",
    "                # assign the cluster number to the voxel\n",
    "                segmentation_base[pos] = cluster_ID\n",
    "\n",
    " \n",
    "        # assign the cluster number to each voxel in the segmentation_test\n",
    "        for cluster_ID in clusters_test.keys():\n",
    "            # get the cluster\n",
    "            cluster = clusters_test[cluster_ID]\n",
    "            # assign the cluster number to each voxel in the segmentation_test\n",
    "            for voxel in cluster:\n",
    "                # find position of voxel in the voxel_list\n",
    "                pos = voxel_list.index(voxel)\n",
    "                # assign the cluster number to the voxel\n",
    "                segmentation_test[pos] = cluster_ID\n",
    "            \n",
    "        ari_score = adjusted_rand_score(segmentation_base, segmentation_test)\n",
    "        new_row = {\n",
    "            'number_of_clusters': number_of_clusters,\n",
    "            'ARI': ari_score,\n",
    "            'comp_name': comp_name,\n",
    "        }\n",
    "        # add new_row to res\n",
    "        res = pd.concat([res, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# save the res\n",
    "res_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\ARI_comparisons.csv\"\n",
    "res.to_csv(res_path, index=False)\n",
    "print('Res saved to: ' + res_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure C - Reproducibility ARI ##\n",
    "\n",
    "\n",
    "# Clear all the variables\n",
    "%reset -f\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mticker   # ← new import\n",
    "reload(figure_utils)\n",
    "\n",
    "figure_letter = 'C'\n",
    "grid_spacing = 0.03\n",
    "\n",
    "stat_to_plot = 'z' # m: mean or z: for z-score\n",
    "comp_names = ['healthy','Knee']\n",
    "save_file = True\n",
    "color_comb = 'white' # tales 'white' or 'black'\n",
    "\n",
    "y_limits_dict = {comp: {'min_y': np.nan, 'max_y': np.nan} for comp in comp_names}\n",
    "# set healthy to 0.40 and 0.70\n",
    "y_limits_dict['healthy']['min_y'] = 0.35\n",
    "y_limits_dict['healthy']['max_y'] = 0.55\n",
    "y_limits_dict['healthy']['marker'] = 'o'\n",
    "y_limits_dict['healthy']['markerfacecolor'] = 'black'   # filled\n",
    "y_limits_dict['healthy']['markeredgecolor'] = 'black'   # filled\n",
    "\n",
    "y_limits_dict['Knee']['min_y'] = 0.35\n",
    "y_limits_dict['Knee']['max_y'] = 0.55\n",
    "y_limits_dict['Knee']['marker'] = 'o'\n",
    "y_limits_dict['Knee']['markerfacecolor'] = 'white'   # open\n",
    "y_limits_dict['Knee']['markeredgecolor'] = 'black'   # open\n",
    "\n",
    "if color_comb == 'white':\n",
    "    opposite_color = 'black'\n",
    "elif color_comb == 'black':\n",
    "    opposite_color = 'white'\n",
    "else:\n",
    "    raise ValueError('color_comb must be white or black')\n",
    "\n",
    "dataset = 'CAPS_K9'\n",
    "experiment = 'CAPS'\n",
    "figure_dims = (10, 1)\n",
    "project_dict = figure_utils.get_project_dict('K9')[0]\n",
    "figures_folder = figure_utils.get_path('Figures', project_dict, figure_letter)\n",
    "res_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\ARI_comparisons.csv\"\n",
    "# Load the res_df\n",
    "res_df = pd.read_csv(res_path)\n",
    "fig, ax = plt.subplots(figsize=figure_dims)\n",
    "\n",
    "for comp in comp_names:\n",
    "    # Make a plot for each stat\n",
    "    res_filtered = res_df[res_df['comp_name'] == comp]   \n",
    "\n",
    "    # create figure\n",
    "    \n",
    "    # get the y values and x values\n",
    "    y_values = res_filtered['ARI'].values\n",
    "    x_values = res_filtered['number_of_clusters'].values\n",
    "    # plot the data\n",
    "    ax.plot(x_values, y_values, marker=y_limits_dict[comp]['marker'], \n",
    "            markerfacecolor=y_limits_dict[comp]['markerfacecolor'], \n",
    "            markeredgecolor=y_limits_dict[comp]['markeredgecolor'], \n",
    "            linestyle='-', label='Data', color=opposite_color)\n",
    "    \n",
    "    # get min_y and max_y\n",
    "    min_y = min(y_values)\n",
    "    max_y = max(y_values)\n",
    "    # define percentage to add to the y-axis\n",
    "    perc = 0.1\n",
    "    \n",
    "    # add 10% of the y-axis\n",
    "    if min_y < 0:\n",
    "        min_y = min_y + min_y*perc\n",
    "    else:\n",
    "        min_y = min_y - min_y*perc\n",
    "    if max_y < 0:\n",
    "        max_y = max_y - max_y*perc\n",
    "    else:\n",
    "        max_y = max_y + max_y*perc\n",
    "    \n",
    "    \n",
    "    # round min_y to the nearest 0.1\n",
    "    min_y = round(min_y - 0.01, 2)\n",
    "    \n",
    "    # round max_y to the nearest 0.1\n",
    "    max_y = round(max_y + 0.01, 2)\n",
    "\n",
    "    # if min_y <= 0.1 make it zero\n",
    "    if min_y <= 0.1:\n",
    "        min_y = 0\n",
    "\n",
    "    # overwrite if limits are not NaN\n",
    "    if not np.isnan(y_limits_dict[comp]['min_y']):\n",
    "        min_y = y_limits_dict[comp]['min_y']\n",
    "    if not np.isnan(y_limits_dict[comp]['max_y']):\n",
    "        max_y = y_limits_dict[comp]['max_y']\n",
    "\n",
    "    # Set the y-axis limits to the min and max of y_values\n",
    "    ax.set_ylim([min_y, max_y])\n",
    "    # ─────────────── y-axis ticks & grid ───────────────\n",
    "    # major ticks: just min and max\n",
    "    ax.yaxis.set_major_locator(mticker.FixedLocator([min_y, max_y]))\n",
    "    # minor ticks: every grid_spacing\n",
    "    ax.yaxis.set_minor_locator(mticker.MultipleLocator(grid_spacing))\n",
    "    # draw grid only at minor ticks\n",
    "    ax.grid(which='minor', color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    # optionally turn off any major grid\n",
    "    ax.grid(which='major', color='none')\n",
    "    \n",
    "    # ensure only major tick labels appear\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "\n",
    "    # Set the background color to none\n",
    "    ax.set_facecolor('none')\n",
    "\n",
    "    for spine in ['top','left','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    # hide x-axis ticks and labels\n",
    "    ax.tick_params(axis='x', colors='none')\n",
    "    # color the y-axis labels\n",
    "    ax.tick_params(axis='y', colors=opposite_color)\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Determine path\n",
    "figure_path = os.path.join(figures_folder, 'K9-' + comp + '_' + 'ARI' + '.png')\n",
    "if save_file:\n",
    "    # Save the figure with transparency\n",
    "    fig.savefig(figure_path, transparent=True)\n",
    "    print('Figure saved to: ' + figure_path)\n",
    "else:\n",
    "    print(figure_path + ' not saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure C - Reproducibility ARI ##\n",
    "# ARI, Generate scatter plot, x number of clusters, y Dice_coeff\n",
    "\n",
    "# Clear all the variables\n",
    "%reset -f\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import figure_utils  # Ensure this is correctly imported or defined\n",
    "from scipy.special import comb\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mticker   # ← new import\n",
    "reload(figure_utils)\n",
    "\n",
    "figure_letter = 'C'\n",
    "grid_spacing = 0.03\n",
    "\n",
    "stat_to_plot = 'z' # m: mean or z: for z-score\n",
    "comp_names = ['healthy','Johnson', 'Johnson_gyri', 'Johnson_lobe']\n",
    "save_file = True\n",
    "color_comb = 'white' # tales 'white' or 'black'\n",
    "\n",
    "y_limits_dict = {comp: {'min_y': np.nan, 'max_y': np.nan} for comp in comp_names}\n",
    "# set healthy to 0.40 and 0.70\n",
    "y_limits_dict['healthy']['min_y'] = 0.35\n",
    "y_limits_dict['healthy']['max_y'] = 0.55\n",
    "\n",
    "if color_comb == 'white':\n",
    "    opposite_color = 'black'\n",
    "elif color_comb == 'black':\n",
    "    opposite_color = 'white'\n",
    "else:\n",
    "    raise ValueError('color_comb must be white or black')\n",
    "\n",
    "dataset = 'CAPS_K9'\n",
    "experiment = 'CAPS'\n",
    "figure_dims = (10, 1)\n",
    "project_dict = figure_utils.get_project_dict('K9')[0]\n",
    "figures_folder = figure_utils.get_path('Figures', project_dict, figure_letter)\n",
    "res_path = r\"C:\\github\\spatially_constrained_spectral_clustering\\results\\ARI.csv\"\n",
    "# Load the res_df\n",
    "res_df = pd.read_csv(res_path)\n",
    "\n",
    "\n",
    "for comp in comp_names:\n",
    "    # Make a plot for each stat\n",
    "    res_filtered = res_df[res_df['comp_name'] == comp]   \n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=figure_dims)\n",
    "    # get the y values and x values\n",
    "    y_values = res_filtered['ARI'].values\n",
    "    x_values = res_filtered['number_of_clusters'].values\n",
    "    # plot the data\n",
    "    ax.plot(x_values, y_values, 'o-', label='Data', color=opposite_color)\n",
    "    \n",
    "    # get min_y and max_y\n",
    "    min_y = min(y_values)\n",
    "    max_y = max(y_values)\n",
    "    # define percentage to add to the y-axis\n",
    "    perc = 0.1\n",
    "    \n",
    "    # add 10% of the y-axis\n",
    "    if min_y < 0:\n",
    "        min_y = min_y + min_y*perc\n",
    "    else:\n",
    "        min_y = min_y - min_y*perc\n",
    "    if max_y < 0:\n",
    "        max_y = max_y - max_y*perc\n",
    "    else:\n",
    "        max_y = max_y + max_y*perc\n",
    "    \n",
    "    \n",
    "    # round min_y to the nearest 0.1\n",
    "    min_y = round(min_y - 0.01, 2)\n",
    "    \n",
    "    # round max_y to the nearest 0.1\n",
    "    max_y = round(max_y + 0.01, 2)\n",
    "\n",
    "    # if min_y <= 0.1 make it zero\n",
    "    if min_y <= 0.1:\n",
    "        min_y = 0\n",
    "\n",
    "    # overwrite if limits are not NaN\n",
    "    if not np.isnan(y_limits_dict[comp]['min_y']):\n",
    "        min_y = y_limits_dict[comp]['min_y']\n",
    "    if not np.isnan(y_limits_dict[comp]['max_y']):\n",
    "        max_y = y_limits_dict[comp]['max_y']\n",
    "\n",
    "    # Set the y-axis limits to the min and max of y_values\n",
    "    ax.set_ylim([min_y, max_y])\n",
    "    # ─────────────── y-axis ticks & grid ───────────────\n",
    "    # major ticks: just min and max\n",
    "    ax.yaxis.set_major_locator(mticker.FixedLocator([min_y, max_y]))\n",
    "    # minor ticks: every grid_spacing\n",
    "    ax.yaxis.set_minor_locator(mticker.MultipleLocator(grid_spacing))\n",
    "    # draw grid only at minor ticks\n",
    "    ax.grid(which='minor', color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    # optionally turn off any major grid\n",
    "    ax.grid(which='major', color='none')\n",
    "    \n",
    "    # ensure only major tick labels appear\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "\n",
    "    # Set the background color to none\n",
    "    ax.set_facecolor('none')\n",
    "\n",
    "    for spine in ['top','left','right','bottom']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    # hide x-axis ticks and labels\n",
    "    ax.tick_params(axis='x', colors='none')\n",
    "    # color the y-axis labels\n",
    "    ax.tick_params(axis='y', colors=opposite_color)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Determine path\n",
    "    figure_path = os.path.join(figures_folder, comp + '_' + 'ARI' + '.png')\n",
    "    if save_file:\n",
    "        # Save the figure with transparency\n",
    "        fig.savefig(figure_path, transparent=True)\n",
    "        print('Figure saved to: ' + figure_path)\n",
    "    else:\n",
    "        print(figure_path + ' not saved')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
